name: MetaWalletGen CLI - Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - unit
        - integration
        - security
        - performance

env:
  PYTHON_VERSION: "3.11"
  PACKAGE_NAME: "metawalletgen-cli"

jobs:
  # Unit Testing
  unit-tests:
    name: ðŸ§ª Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11", "3.12"]
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: ðŸ§ª Run unit tests
      run: |
        pip install pytest pytest-cov pytest-xdist
        pytest tests/ -v --cov=metawalletgen --cov-report=xml --cov-report=html --cov-report=term-missing -n auto
    
    - name: ðŸ“Š Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # Integration Testing
  integration-tests:
    name: ðŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: ðŸ§ª Run integration tests
      run: |
        pip install pytest pytest-cov
        pytest tests/ -m "integration" -v --cov=metawalletgen --cov-report=term-missing

  # Security Testing
  security-tests:
    name: ðŸ”’ Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ” Security scan with Bandit
      run: |
        pip install bandit safety
        bandit -r metawalletgen -f json -o bandit-report.json || true
        safety check --json --output safety-report.json || true
    
    - name: ðŸ” Dependency vulnerability scan
      run: |
        pip install pip-audit
        pip-audit --format json --output pip-audit-report.json || true
    
    - name: ðŸ“Š Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          pip-audit-report.json

  # Performance Testing
  performance-tests:
    name: ðŸ“Š Performance Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'performance' || github.event.inputs.test_type == 'all'
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: ðŸƒ Run performance benchmarks
      run: |
        pip install pytest-benchmark
        pytest --benchmark-only --benchmark-sort=mean --benchmark-min-rounds=10
    
    - name: ðŸ“Š Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: .pytest_cache/

  # Cross-Platform Testing
  cross-platform-tests:
    name: ðŸŒ Cross-Platform Tests
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.8", "3.11"]
    
    steps:
    - name: ðŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: ðŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: ðŸ§ª Run cross-platform tests
      run: |
        pip install pytest pytest-cov
        pytest tests/ -v --cov=metawalletgen --cov-report=term-missing

  # Test Summary
  test-summary:
    name: ðŸ“‹ Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, cross-platform-tests]
    if: always()
    
    steps:
    - name: ðŸ“Š Generate test summary
      run: |
        echo "## ðŸ§ª Test Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "### Integration Tests: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "### Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "### Cross-Platform Tests: ${{ needs.cross-platform-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.unit-tests.result }}" == "success" && "${{ needs.integration-tests.result }}" == "success" && "${{ needs.security-tests.result }}" == "success" && "${{ needs.cross-platform-tests.result }}" == "success" ]]; then
          echo "ðŸŽ‰ **All tests passed successfully!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Some tests failed. Please check the logs above.**" >> $GITHUB_STEP_SUMMARY
        fi
